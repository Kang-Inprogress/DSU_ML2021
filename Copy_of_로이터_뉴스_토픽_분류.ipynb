{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 로이터 뉴스 토픽 분류.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZM+heqS9ebq7R1gn2XnIo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kang-Inprogress/DSU_ML2021/blob/main/Copy_of_%EB%A1%9C%EC%9D%B4%ED%84%B0_%EB%89%B4%EC%8A%A4_%ED%86%A0%ED%94%BD_%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLOGl-1OtIjB"
      },
      "source": [
        "데이터 정보:\n",
        "46가지 토픽으로 라벨이 달린 11,228개의 로이터 뉴스(기사)로 이루어진 데이터셋"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9dH035D1jDN"
      },
      "source": [
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\") 를 사용해서 단어와 매칭되는 인덱스번호(number)를 알 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4znggJgU1dOv"
      },
      "source": [
        " # 데이터 준비\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words = 10000, test_split = 0.2) # 빈도를 내림차순으로 10000개까지만 로드한다\n",
        "\n",
        "# print('훈련용 뉴스 기사 : {}'.format(len(x_train)))\n",
        "# print('테스트용 뉴스 기사 : {}'.format(len(x_test)))\n",
        "# num_classes = max(y_train) + 1\n",
        "# print('카테고리 : {}'.format(num_classes))\n",
        "# 훈련 셋: 8982개(80%), 테스트 셋: 2246개(20%), 카테고리(label): 46개\n",
        "\n",
        "# 데이터를 벡터화\n",
        "def vertorize_sequences(sequences, dimension = 10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequences in enumerate(sequences):\n",
        "    results[i, sequence] = 1.\n",
        "  return results\n",
        "\n",
        "x_train = vectorize_sequences(x_train)\n",
        "x_test = vectorize_sequences(x_test)\n",
        "# label 원 핫 코드화\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 46)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 46)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5GlEuCqZw3e"
      },
      "source": [
        "컴퓨터는 자연어를 처리할때 어떤 의미로 사용되었는지 문맥을 통해 바로 구분할 수 있지만, 컴퓨터는 그렇지 못하다. \n",
        "\n",
        "텍스트를 숫자로 표현해서 기계가 이해할 수 있도록 해야한다. 그것이 바로 **벡터화**이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4Gag5RRXCvS"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "n_input = 64\n",
        "n_hidden = 64\n",
        "n_output = 46\n",
        "\n",
        "mlp = Sequential()\n",
        "mlp.add(Dense(units = n_hidden, activition=\"tanh\", input_shape(n_input, ), kernel_initializer = \"random_uniform\", bias_initializer = \"zeros\"))\n",
        "mlp.add(Dense(units = n_output, activition=\"softmax\", kernel_initializer = \"random_uniform\", bias_initializer = \"zeros\"))\n",
        "mlp.compile(loss = \"mse\", optimizers = Adam(learning_rate = 0.001), validation_data = (x_test, y_test), verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}